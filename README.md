#  Living Minhwa: Generative AI for Korean Folk Painting
### "ì‚´ì•„ìˆëŠ” ë¯¼í™”: í•œêµ­ ì „í†µ ì˜ˆìˆ ì˜ ìƒì„±í˜• AI ë³µì› ë° ë¯¸ë””ì–´ ì•„íŠ¸í™” í”„ë¡œì íŠ¸"

![Python](https://img.shields.io/badge/Python-3.10-blue?style=flat&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-ee4c2c?style=flat&logo=pytorch&logoColor=white)
![Diffusers](https://img.shields.io/badge/HuggingFace-Diffusers-yellow?style=flat&logo=huggingface&logoColor=white)
![ComfyUI](https://img.shields.io/badge/Tool-ComfyUI-purple?style=flat)
![License](https://img.shields.io/badge/License-MIT-green?style=flat)

##  Project Overview

ì´ í”„ë¡œì íŠ¸ëŠ” **Stable Diffusion**ê³¼ **LoRA(Low-Rank Adaptation)** ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ í•œêµ­ì˜ ì „í†µ 'ë¯¼í™”' ìŠ¤íƒ€ì¼ì„ í•™ìŠµí•˜ê³ , Stable Video Diffusion (SVD)ë¥¼ í†µí•´ ì •ì ì¸ ë¯¼í™”ë¥¼ ë™ì ì¸ Media Artë¡œ í™•ì¥í•˜ëŠ” **Multimodal Generative AI** í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

ë‹¨ìˆœí•œ ì´ë¯¸ì§€ ìƒì„±ì„ ë„˜ì–´, í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ë¯¼í™”ë¥¼ ì°½ì‘í•˜ê³ , ì´ë¥¼ ë‹¤ì‹œ ì˜ìƒìœ¼ë¡œ ë³€í™˜í•¨ìœ¼ë¡œì¨ ìŠí˜€ì ¸ ê°€ëŠ” ì „í†µ ì˜ˆìˆ ì— ìƒˆë¡œìš´ ë””ì§€í„¸ ê°€ì¹˜ë¥¼ ë¶€ì—¬í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

###  Objective & Motivation
* **Problem:** ê¸°ì¡´ ìƒì„± ëª¨ë¸(SD 1.5)ì€ ì„œì–‘ í™”í’ì— í¸í–¥ë˜ì–´ ìˆì–´, 'í•œêµ­ í˜¸ë‘ì´'ë‚˜ 'ì†Œë‚˜ë¬´'ë¥¼ ê·¸ë¦´ ë•Œ ë¯¼í™” íŠ¹ìœ ì˜ í•´í•™ì  ëŠë‚Œê³¼ ë¶“í„°ì¹˜ ì§ˆê°ì„ ì‚´ë¦¬ì§€ ëª»í•¨.
* **Solution:** ê³µê³µ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ì €ì‘ê¶Œ ë¬¸ì œì—†ëŠ” 'ë¯¼í™” ì „ìš© LoRA'ë¥¼ ì œì‘í•˜ê³ , ìµœì‹  SVD ê¸°ìˆ ë¡œ ìƒë™ê°ì„ ë¶€ì—¬.
* **Key Tech:** `Stable Diffusion v1.5`, `LoRA`, `Stable Video Diffusion (SVD)`, `High-quality Captioning`.

---

##  Dataset Preparation (ë°ì´í„° ì œì‘ ê³¼ì •) 
ë³¸ í”„ë¡œì íŠ¸ì˜ í•µì‹¬ì€ **ê³ í’ˆì§ˆì˜ ìì²´ ë°ì´í„°ì…‹ êµ¬ì¶•**ì— ìˆìŠµë‹ˆë‹¤.

### 1. Data Collection (ìˆ˜ì§‘)
* **Source:** [e-ë®¤ì§€ì—„](https://www.emuseum.go.kr/), [êµ­ë¦½ì¤‘ì•™ë°•ë¬¼ê´€](https://www.museum.go.kr/)
* **Selection:** ì €ì‘ê¶Œ ë¬¸ì œê°€ ì—†ëŠ” **'ê³µê³µëˆ„ë¦¬ ì œ1ìœ í˜•(ì¶œì²˜í‘œì‹œ)'** ë° **'ì €ì‘ê¶Œ ë§Œë£Œ'** ë¯¼í™” ì´ë¯¸ì§€ 50ì¥ì„ ì—„ì„ í–ˆìŠµë‹ˆë‹¤. (ì£¼ë¡œ í™”ì¡°ë„, ì‘í˜¸ë„)

### 2. Preprocessing (ì „ì²˜ë¦¬)
* **Resizing:** í•™ìŠµ íš¨ìœ¨ì„ ìœ„í•´ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ `512x512` í”½ì…€ë¡œ Center Crop ë° Resize.
* **Cleaning:** ì°¢ì–´ì§€ê±°ë‚˜ ì˜¤ì—¼ì´ ì‹¬í•œ ë¶€ë¶„ì€ í¬í† ìƒµìœ¼ë¡œ ì¼ë¶€ ë³´ì •.

### 3. Custom Captioning (ìº¡ì…˜ ì œì‘)
ë‹¨ìˆœ ìë™ ìº¡ì…˜ì´ ì•„ë‹Œ, ìŠ¤íƒ€ì¼ í•™ìŠµì„ ìœ„í•œ ì •êµí•œ ìº¡ì…˜ì„ ì§ì ‘ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.
* **Trigger word:** minhwa style(ì´ ë‹¨ì–´ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•´ì•¼ ì‘ë™í•©ë‹ˆë‹¤)
* **Process:** `BLIP` ëª¨ë¸ ì´ˆì•ˆ ìƒì„± -> **ì‚¬ëŒì´ ì§ì ‘ ìˆ˜ì •(Human-in-the-loop)**
* **Format:** `[Trigger Word], [Subject], [Background], [Style Description]`
* **Example:**
    * *Before (BLIP):* "A tiger standing next to a tree."
    * *After (Custom):* "**minhwa style**, a humorous tiger with big eyes, standing next to a pine tree, traditional korean paper texture, old paper background."

---

##  Training (í•™ìŠµ ì •ë³´)

* **Base model:** runwayml/stable-diffusion-v1-5
* **Method:** LoRA (Low-Rank Adaptation) via Kohya_ss
* **Environment:** NVIDIA RTX 4060 Laptop (8GB VRAM)
* **Train Script:** `diffusers` examples or `kohya_ss`
* **Hyperparameters:**
    * `learning_rate`: 1e-4
    * `batch_size`: 1
    * `max_train_steps`: 1500
    * `mixed_precision`: fp16
 
## ğŸš€ Workflow & Pipeline

ë³¸ í”„ë¡œì íŠ¸ëŠ” ë°ì´í„° ìˆ˜ì§‘ë¶€í„° ì˜ìƒ ìƒì„±ê¹Œì§€ ì´ 4ë‹¨ê³„ì˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

```mermaid
graph LR
    A[Data Collection<br>e-Museum] --> B[Preprocessing<br>Crop & Captioning]
    B --> C[LoRA Fine-tuning<br>Stable Diffusion]
    C --> D[Inference<br>Text-to-Image]
    D --> E[Image-to-Video<br>SVD via ComfyUI]
